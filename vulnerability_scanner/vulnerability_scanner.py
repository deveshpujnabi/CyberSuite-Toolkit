# vulnerability_scanner/vulnerability_scanner.py
import requests
from bs4 import BeautifulSoup

def vulnerability_scanner(url):
    """
    Scans a website for common vulnerabilities like outdated software, misconfigurations, and directory listing.
    
    Args:
        url (str): The website URL to scan.
    
    Returns:
        str: Scan results or error message.
    """
    vulnerabilities = []

    try:
        response = requests.get(url, timeout=10)
        report = f"[+] Connected to {url}\n"

        server_header = response.headers.get('Server')
        if server_header:
            report += f"[*] Detected Server: {server_header}\n"
            vulnerabilities.extend(check_server_version(server_header))
        else:
            report += "[-] No 'Server' header found.\n"

        if is_directory_listing_enabled(url):
            vulnerabilities.append("Directory listing is enabled.")

        if 'X-Content-Type-Options' not in response.headers:
            vulnerabilities.append("X-Content-Type-Options header is missing.")

        html_vulnerabilities = scan_meta_tags(response.text)
        vulnerabilities.extend(html_vulnerabilities)

        if vulnerabilities:
            report += "\n[!] Vulnerabilities Found:\n"
            for vuln in vulnerabilities:
                report += f"  - {vuln}\n"
        else:
            report += "\n[+] No vulnerabilities detected.\n"

    except requests.RequestException as e:
        report = f"[-] Error connecting to {url}: {e}"

    return report


def check_server_version(server_header):
    issues = []
    if "Apache" in server_header:
        version = server_header.split('/')[1] if '/' in server_header else "Unknown"
        if version and version != "Unknown":
            if version < "2.4.57":
                issues.append(f"Outdated Apache version: {version}")
    return issues


def is_directory_listing_enabled(url):
    test_url = f"{url.rstrip('/')}/test-dir"
    try:
        response = requests.get(test_url)
        if response.status_code == 200 and "Index of" in response.text:
            return True
    except requests.RequestException:
        pass
    return False


def scan_meta_tags(html_content):
    issues = []
    soup = BeautifulSoup(html_content, 'html.parser')
    meta_tags = soup.find_all("meta")
    for tag in meta_tags:
        if "generator" in tag.attrs.get("name", "").lower():
            generator_content = tag.attrs.get("content", "").lower()
            if "wordpress" in generator_content and "6.3" not in generator_content:
                issues.append(f"Outdated WordPress version: {generator_content}")
    return issues
